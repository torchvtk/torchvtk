

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>TorchQueueDataset &mdash; torchvtk v0.2.5 documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script type="text/javascript" src="_static/jquery.js"></script>
        <script type="text/javascript" src="_static/underscore.js"></script>
        <script type="text/javascript" src="_static/doctools.js"></script>
        <script type="text/javascript" src="_static/language_data.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Transforms" href="Transforms.html" />
    <link rel="prev" title="TorchDataset" href="TorchDataset.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home" alt="Documentation Home"> torchvtk
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Documentation:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="TorchDataset.html">TorchDataset</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">TorchQueueDataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="Transforms.html">Transforms</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">torchvtk</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>TorchQueueDataset</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/TorchQueueDataset.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="torchqueuedataset">
<h1>TorchQueueDataset<a class="headerlink" href="#torchqueuedataset" title="Permalink to this headline">¶</a></h1>
<p>This Dataset holds a queue of items in memory. Being an iterable-style dataset set, it samples batches from the available queue upon demand. The queue is filled using background threads and has different filling modes.
Depending on how fast you can actually load your data compared to running your network, you might want to advance the queue by one item upon sampling (if your SSD/hard drives are fast enough). In this case use <code class="docutils literal notranslate"><span class="pre">mode=&quot;onsample&quot;</span></code>. If you find that data loading is your bottleneck, try to make the queue as big as possible and use <code class="docutils literal notranslate"><span class="pre">mode=&quot;always&quot;</span></code>. This will just keep pushing new items to your queue as fast as possible, removing old ones. If your network is generally faster, this is the desired way to get the most uniform sampling frequencies for all your items.</p>
<p>Here is a sampling frequency histogram using <code class="docutils literal notranslate"><span class="pre">mode='onsample'</span></code> for 80k samplings of the CQ500 dataset (320 items) on a machine with slow network HDD storage. For this particular setup we increased our training speed from <code class="docutils literal notranslate"><span class="pre">~5s/it</span></code> to <code class="docutils literal notranslate"><span class="pre">2it/s</span></code> through the use of the queue (10x), while keeping the sampling mostly uniform.
<img alt="Sampling Frequency Histogram" src="_images/queue_sampling_frequency.png" /></p>
<span class="target" id="module-torchvtk.datasets"></span><dl class="class">
<dt id="torchvtk.datasets.TorchQueueDataset">
<em class="property">class </em><code class="sig-prename descclassname">torchvtk.datasets.</code><code class="sig-name descname">TorchQueueDataset</code><span class="sig-paren">(</span><em class="sig-param">torch_ds</em>, <em class="sig-param">epoch_len=1000</em>, <em class="sig-param">mode='onsample'</em>, <em class="sig-param">fill_interval=None</em>, <em class="sig-param">num_workers=1</em>, <em class="sig-param">q_maxlen=None</em>, <em class="sig-param">ram_use=0.75</em>, <em class="sig-param">wait_fill=True</em>, <em class="sig-param">wait_fill_timeout=60</em>, <em class="sig-param">sample_tfm=&lt;function noop&gt;</em>, <em class="sig-param">batch_tfm=&lt;function noop&gt;</em>, <em class="sig-param">bs=1</em>, <em class="sig-param">collate_fn=&lt;function dict_collate_fn&gt;</em>, <em class="sig-param">log_sampling=False</em>, <em class="sig-param">avg_item_size=None</em>, <em class="sig-param">preprocess_fn=None</em>, <em class="sig-param">filter_fn=None</em><span class="sig-paren">)</span><a class="headerlink" href="#torchvtk.datasets.TorchQueueDataset" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.data.IterableDataset</span></code></p>
<dl class="method">
<dt id="torchvtk.datasets.TorchQueueDataset.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param">torch_ds</em>, <em class="sig-param">epoch_len=1000</em>, <em class="sig-param">mode='onsample'</em>, <em class="sig-param">fill_interval=None</em>, <em class="sig-param">num_workers=1</em>, <em class="sig-param">q_maxlen=None</em>, <em class="sig-param">ram_use=0.75</em>, <em class="sig-param">wait_fill=True</em>, <em class="sig-param">wait_fill_timeout=60</em>, <em class="sig-param">sample_tfm=&lt;function noop&gt;</em>, <em class="sig-param">batch_tfm=&lt;function noop&gt;</em>, <em class="sig-param">bs=1</em>, <em class="sig-param">collate_fn=&lt;function dict_collate_fn&gt;</em>, <em class="sig-param">log_sampling=False</em>, <em class="sig-param">avg_item_size=None</em>, <em class="sig-param">preprocess_fn=None</em>, <em class="sig-param">filter_fn=None</em><span class="sig-paren">)</span><a class="headerlink" href="#torchvtk.datasets.TorchQueueDataset.__init__" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>torch_ds</strong> (<a class="reference internal" href="TorchDataset.html#torchvtk.datasets.TorchDataset" title="torchvtk.datasets.TorchDataset"><em>TorchDataset</em></a><em>, </em><em>str</em><em>,</em><em>Path</em>) – A TorchDataset to be used for queueing or path to the dataset on disk</p></li>
<li><p><strong>mode</strong> (<em>string</em>) – Queue filling mode.
- ‘onsample’ refills the queue after it got sampled
- ‘always’ keeps refilling the queue as fast as possible
- ‘interval’ refills the queue regularly. Set fill_interval</p></li>
<li><p><strong>fill_interval</strong> (<em>float</em>) – Time intervals in seconds between queue fillings</p></li>
<li><p><strong>num_workers</strong> (<em>int</em>) – Number of threads loading in data</p></li>
<li><p><strong>q_maxlen</strong> (<em>int</em>) – Set queue size. Overrides <cite>ram_use</cite></p></li>
<li><p><strong>ram_use</strong> (<em>float</em>) – Fraction of available system memory to use for queue or memory budget in MB (&gt;1.0). Default is 75%</p></li>
<li><p><strong>wait_fill</strong> (<em>int</em><em>, </em><em>bool</em>) – Boolean whether queue should be filled on init or Int to fill the queue at least with a certain amount of items</p></li>
<li><p><strong>wait_fill_timeout</strong> (<em>int</em><em>,</em><em>float</em>) – Time in seconds until wait_fill timeouts. Default is 60s</p></li>
<li><p><strong>sample_tfm</strong> (<em>Transform</em><em>, </em><em>function</em>) – Applicable transform (receiving and producing a dict) that is applied upon sampling from the queue</p></li>
<li><p><strong>batch_tfm</strong> (<em>Transform</em><em>, </em><em>function</em>) – Transforms to be applied on batches of items</p></li>
<li><p><strong>preprocess_fn</strong> (<em>function</em>) – Override preprocess_fn from given torch_ds</p></li>
<li><p><strong>filter_fn</strong> (<em>function</em>) – Filters filenames to load, like TorchDataset. Only used if <cite>torch_ds</cite> is a path to a dataset.</p></li>
<li><p><strong>bs</strong> (<em>int</em>) – Batch Size</p></li>
<li><p><strong>collate_fn</strong> (<em>function</em>) – Collate Function to merge items to batches. Default assumes dictionaries (like from TorchDataset) and stacks all tensors, while collecting non-tensors in a list</p></li>
<li><p><strong>avg_item_size</strong> (<em>float</em><em>, </em><em>torch.Tensor</em>) – Example tensor or size in MB</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torchvtk.datasets.TorchQueueDataset.batch_generator">
<code class="sig-name descname">batch_generator</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#torchvtk.datasets.TorchQueueDataset.batch_generator" title="Permalink to this definition">¶</a></dt>
<dd><p>Generator for sampling the queue.
This makes use of the object attributes bs (batch size) and the collate function
Returns: Generator that samples randomly samples batches from the queue.</p>
</dd></dl>

<dl class="method">
<dt id="torchvtk.datasets.TorchQueueDataset.get_dataloader">
<code class="sig-name descname">get_dataloader</code><span class="sig-paren">(</span><em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#torchvtk.datasets.TorchQueueDataset.get_dataloader" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torchvtk.datasets.TorchQueueDataset.qsize">
<em class="property">property </em><code class="sig-name descname">qsize</code><a class="headerlink" href="#torchvtk.datasets.TorchQueueDataset.qsize" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torchvtk.datasets.TorchQueueDataset.wait_fill_queue">
<code class="sig-name descname">wait_fill_queue</code><span class="sig-paren">(</span><em class="sig-param">fill_atleast=None</em>, <em class="sig-param">timeout=60</em>, <em class="sig-param">polling_interval=0.25</em><span class="sig-paren">)</span><a class="headerlink" href="#torchvtk.datasets.TorchQueueDataset.wait_fill_queue" title="Permalink to this definition">¶</a></dt>
<dd><p>Waits untill the queue is filled (<cite>fill_atleast`=None) or until filled with at least `fill_atleast</cite>. Timeouts.
:param fill_atleast: Waits until queue is at least filled with so many items.
:type fill_atleast: int
:param timeout: Time in seconds before this method terminates regardless of the queue size
:type timeout: Number
:param polling_interval: Time in seconds how fast the queue size is polled while waiting.
:type polling_interval: Number</p>
</dd></dl>

</dd></dl>

</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="Transforms.html" class="btn btn-neutral float-right" title="Transforms" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="TorchDataset.html" class="btn btn-neutral float-left" title="TorchDataset" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2020, Dominik Engel, Marc Fabian Mezger

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>